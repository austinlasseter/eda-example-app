{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.io as pio\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve, roc_auc_score, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the color palette (17 colors).\n",
    "Viridis= ['#440154', '#48186a', '#472d7b', '#424086', '#3b528b', '#33638d', '#2c728e', '#26828e', '#21918c', '#1fa088',\n",
    "          '#28ae80', '#3fbc73', '#5ec962', '#84d44b', '#addc30','#d8e219', '#fde725']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93701, 39)\n"
     ]
    }
   ],
   "source": [
    "# read clean datafile\n",
    "df = pd.read_csv('../data/dataset5.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this many predictors, overfitting is definitely a risk. We'll take 5 steps to avoid overfit:\n",
    "* standardize the predictors (i.e., scale variables to between 0 and 1)\n",
    "* regularization (apply a penalty to large coefficients)\n",
    "* apply kfold cross-validation\n",
    "* use gridsearch to determine the optimal hyperparameters for our model\n",
    "* compare multiple models and select the one with the best evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with imbalanced classes in the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our target variable (failure) is highly imbalanced, we need to take several precautions to accurately evaluate our model. Because the data is overwhelmingly positive, a model that predicted \"no failure\" would be accurate 99% of the time! We will take two steps to deal with imbalance:  \n",
    "* Up-sample Minority Class\n",
    "* Use ROC-AUC and F1 as our performance metric rather than accuracy  \n",
    "https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we need to resample, we'll conduct train-test split _before_ separating our X and y data. This is because we only want to oversample the training data, not the testing data! In addition, if we conducted oversampling _before_ the train-test split, we would almost certainly have duplicate data in both the training and testing sets, which would result in severe overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "df_train, df_test = train_test_split(df, test_size = .3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple methods for oversampling the training data. One technique available in scikit learn is [SMOTE - Synthetic Minority Over-sampling Technique](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html), but we'll just use random sampling with replacement (i.e., resampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    65524\n",
       "0    65524\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train['failure']==0]\n",
    "df_minority = df_train[df_train['failure']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_train_upsampled['failure'].value_counts()\n",
    "# hat tip: https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `y1_test` later on, for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final x-values (features)\n",
    "X_train=df_train_upsampled.drop(['failure', 'device'], axis=1)\n",
    "X_test=df_test.drop(['failure', 'device'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final y-values\n",
    "y_train=df_train_upsampled['failure'].values\n",
    "y1_test=df_test[['device','failure']] # Hold onto the device variable for later use, but remove it from the modeling data.\n",
    "y_test=df_test['failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that lengths match\n",
    "assert len(X_train)==len(y_train)\n",
    "assert len(X_test)==len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary model exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preliminary step, we'll take a look at four popular classifiers (naive bayes, KNN, logistic, and random forest) and see how they handle our data using the default hyperparameters. This will help us determine which model to select for further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0045\n",
      "Accuracy 0.7784\n",
      "AUC Score 0.6693\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "# Fit on the training data\n",
    "gnb_model = gnb.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=gnb_model.predict(X_test)\n",
    "probabilities = gnb_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_nb=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_nb = metrics.accuracy_score(y_test, predictions)\n",
    "f1_nb = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_nb,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_nb,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_nb,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0109\n",
      "Accuracy 0.8901\n",
      "AUC Score 0.7852\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "# Fit on the training data\n",
    "log_model=logreg.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=log_model.predict(X_test)\n",
    "probabilities = log_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_log=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_log = metrics.accuracy_score(y_test, predictions)\n",
    "f1_log = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_log,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_log,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_log,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0202\n",
      "Accuracy 0.9965\n",
      "AUC Score 0.5187\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "# Fit on the training data\n",
    "knn_model=knn.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=knn_model.predict(X_test)\n",
    "probabilities = knn_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_knn=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_knn = metrics.accuracy_score(y_test, predictions)\n",
    "f1_knn = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_knn,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_knn,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_knn,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0000\n",
      "Accuracy 0.9990\n",
      "AUC Score 0.4999\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# Fit on the training data\n",
    "rf_model=rf.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=rf_model.predict(X_test)\n",
    "probabilities = rf_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_rf=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_rf = metrics.accuracy_score(y_test, predictions)\n",
    "f1_rf = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_rf,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_rf,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_rf,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Four Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, it appears that the `random forest` and `KNN` models are the best - they have accuracy scores of nearly 100%. But of course this is misleading - imbalanced classes typically result in high accuracy, since this score simply measures the number of correct predictions over the number of all test observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better metric for comparison in this case is the [\"receiver operator characteristic - area under the curve\"](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) or `ROC AUC` score. It measures the balance between the true positive rate and the false positive rate.\n",
    "* true positive rate: TP/ (TP + FN) -- also known as `recall`\n",
    "* false positive rate: FP / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric to keep in mind is the F1 score. This score ranges from 0 to 1 and is an overall measure of a model’s accuracy that combines recall and precision. A higher F1 score means that the model has low false positives and low false negatives. Our models have an F1 score near zero, which is why we'll take a look at neural nets next.\n",
    "* precision: TP/ (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[f1_nb, f1_log, f1_knn, f1_rf]\n",
    "acc=[acc_nb, acc_log, acc_knn, acc_rf]\n",
    "auc=[auc_nb, auc_log, auc_knn, auc_rf]\n",
    "models=['naive bayes', 'logistic regression', 'k-nearest neighbors', 'random forest']\n",
    "index=['F1 score', 'Accuracy', 'AUC score']\n",
    "results=pd.DataFrame([f1, acc, auc], index=index, columns=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive bayes</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>k-nearest neighbors</th>\n",
       "      <th>random forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.778450</td>\n",
       "      <td>0.890114</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.999004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC score</th>\n",
       "      <td>0.669322</td>\n",
       "      <td>0.785151</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.499947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           naive bayes  logistic regression  k-nearest neighbors  \\\n",
       "F1 score      0.004476             0.010887             0.020202   \n",
       "Accuracy      0.778450             0.890114             0.996549   \n",
       "AUC score     0.669322             0.785151             0.518700   \n",
       "\n",
       "           random forest  \n",
       "F1 score        0.000000  \n",
       "Accuracy        0.999004  \n",
       "AUC score       0.499947  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle those results for comparison with tensorflow.\n",
    "with open('model_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "#fde725"
         },
         "name": "F1 score",
         "type": "bar",
         "uid": "bf3ebba1-d114-477b-8512-7511e6201098",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.004475703324808184,
          0.010886967659301952,
          0.0202020202020202,
          0
         ]
        },
        {
         "marker": {
          "color": "#28ae80"
         },
         "name": "Accuracy",
         "type": "bar",
         "uid": "fcd1b311-45d4-40f1-80a7-4686a7207a8b",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.7784497171925581,
          0.8901141901746648,
          0.9965493934758636,
          0.999003948632208
         ]
        },
        {
         "marker": {
          "color": "#440154"
         },
         "name": "AUC score",
         "type": "bar",
         "uid": "4cbaf099-6332-481b-9d78-63a91eea2f78",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.6693220821761732,
          0.7851506088442641,
          0.5187004201381471,
          0.499946592608417
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Comparison of Possible Models"
        },
        "xaxis": {
         "title": {
          "text": "Predictive models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Score"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\")) {\n",
       "    Plotly.newPlot(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\", [{\"marker\": {\"color\": \"#fde725\"}, \"name\": \"F1 score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.004475703324808184, 0.010886967659301952, 0.0202020202020202, 0.0], \"type\": \"bar\", \"uid\": \"bf3ebba1-d114-477b-8512-7511e6201098\"}, {\"marker\": {\"color\": \"#28ae80\"}, \"name\": \"Accuracy\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.7784497171925581, 0.8901141901746648, 0.9965493934758636, 0.999003948632208], \"type\": \"bar\", \"uid\": \"fcd1b311-45d4-40f1-80a7-4686a7207a8b\"}, {\"marker\": {\"color\": \"#440154\"}, \"name\": \"AUC score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.6693220821761732, 0.7851506088442641, 0.5187004201381471, 0.499946592608417], \"type\": \"bar\", \"uid\": \"4cbaf099-6332-481b-9d78-63a91eea2f78\"}], {\"title\": {\"text\": \"Comparison of Possible Models\"}, \"xaxis\": {\"title\": {\"text\": \"Predictive models\"}}, \"yaxis\": {\"title\": {\"text\": \"Score\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\")) {window._Plotly.Plots.resize(document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\")) {\n",
       "    Plotly.newPlot(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\", [{\"marker\": {\"color\": \"#fde725\"}, \"name\": \"F1 score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.004475703324808184, 0.010886967659301952, 0.0202020202020202, 0.0], \"type\": \"bar\", \"uid\": \"bf3ebba1-d114-477b-8512-7511e6201098\"}, {\"marker\": {\"color\": \"#28ae80\"}, \"name\": \"Accuracy\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.7784497171925581, 0.8901141901746648, 0.9965493934758636, 0.999003948632208], \"type\": \"bar\", \"uid\": \"fcd1b311-45d4-40f1-80a7-4686a7207a8b\"}, {\"marker\": {\"color\": \"#440154\"}, \"name\": \"AUC score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.6693220821761732, 0.7851506088442641, 0.5187004201381471, 0.499946592608417], \"type\": \"bar\", \"uid\": \"4cbaf099-6332-481b-9d78-63a91eea2f78\"}], {\"title\": {\"text\": \"Comparison of Possible Models\"}, \"xaxis\": {\"title\": {\"text\": \"Predictive models\"}}, \"yaxis\": {\"title\": {\"text\": \"Score\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\")) {window._Plotly.Plots.resize(document.getElementById(\"1b09e1df-73e4-44f2-9f0b-955dfd8d199f\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display that with plotly.\n",
    "mydata1 = go.Bar(\n",
    "    x=results.loc['F1 score'].index,\n",
    "    y=results.loc['F1 score'],\n",
    "    name=results.index[0],\n",
    "    marker=dict(color=Viridis[16])\n",
    ")\n",
    "mydata2 = go.Bar(\n",
    "    x=results.loc['Accuracy'].index,\n",
    "    y=results.loc['Accuracy'],\n",
    "    name=results.index[1],\n",
    "    marker=dict(color=Viridis[10])\n",
    ")\n",
    "mydata3 = go.Bar(\n",
    "    x=results.loc['AUC score'].index,\n",
    "    y=results.loc['AUC score'],\n",
    "    name=results.index[2],\n",
    "    marker=dict(color=Viridis[0])\n",
    ")\n",
    "mylayout = go.Layout(\n",
    "    title='Comparison of Possible Models',\n",
    "    xaxis = dict(title = 'Predictive models'), # x-axis label\n",
    "    yaxis = dict(title = 'Score'), # y-axis label\n",
    "    \n",
    ")\n",
    "fig = go.Figure(data=[mydata1, mydata2, mydata3], layout=mylayout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the four models we tried, logistic regression has the highest ROC-AUC score, so we'll continue improving this model by tuning the hyperparameters and applying crossvalidation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch is a method to examine multiple versions of the same model, with different parameters, to determine which has the highest evaluation metrics. This cell is commented out, and its results pickled, because it is very time-consuming to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create regularization penalty space (l1=ridge, l2=lasso)\n",
    "# penalty = ['l1', 'l2'] \n",
    "\n",
    "# # Create regularization hyperparameter space\n",
    "# C = np.logspace(0, 4, 10)\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# # Create grid search using 5-fold cross validation\n",
    "# grid_lr = GridSearchCV(LogisticRegression(), hyperparameters, cv=5,  n_jobs = 1, verbose=0)\n",
    "# grid_lr.fit(X_train, y_train)\n",
    "# print(grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model using those parameters\n",
    "# log_model = grid_lr.best_estimator_\n",
    "\n",
    "# # Pickle the results of gridsearch so we don't have to do that again!\n",
    "# with open('logistic_best_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(log_model, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic regression model includes two important features to help avoid overfit:\n",
    "* [L2 penalty](https://towardsdatascience.com/ridge-regression-for-better-usage-2f19b3a202db) (aka `Ridge Regression`). It penalizes larger coefficients, which are frequently associated with overfit.\n",
    "* [C parameter](https://charleshsliao.wordpress.com/2017/05/20/logistic-regression-in-python-to-tune-parameter-c/) for regularization. C is actually the inverse of regularization strength (lambda) which shrinks larger coefficients towards zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1291.5496650148827, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Unpickle the results of gridsearch\n",
    "pickle_off = open('logistic_best_params.pkl','rb')\n",
    "log_model = pickle.load(pickle_off)\n",
    "print(log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing data\n",
    "predictions=log_model.predict(X_test)\n",
    "probabilities = log_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit learn` provides several metrics for evaluating the precision and accuracy of our model. Let's combine all of them into a single reusable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC score': 0.7851862137719862,\n",
       " 'accuracy score': 0.8901853367009356,\n",
       " 'error rate': 0.10981466329906442,\n",
       " 'f1 score': 0.010893944248638257,\n",
       " 'precision score': 0.005490956072351421,\n",
       " 'recall score': 0.68}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full list of metrics\n",
    "def model_metrics(y_test, predictions):\n",
    "    '''\n",
    "    Calculate 5 standard model metrics\n",
    "    Return a dictionary with the metrics\n",
    "    '''\n",
    "    f1 = metrics.f1_score(y_test, predictions)\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    error = 1 - accuracy\n",
    "    precision = metrics.precision_score(y_test, predictions)\n",
    "    recall = metrics.recall_score(y_test, predictions)\n",
    "    rocauc =  metrics.roc_auc_score(y_test, predictions)\n",
    "    return {'f1 score':f1, 'accuracy score': accuracy, 'error rate': error, 'precision score': precision, 'recall score': recall, 'ROC-AUC score': rocauc}\n",
    "\n",
    "model_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC (Receiver Operating Characteristic - Area Under the Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a deeper dive into the ROC-AUC score, and display it as a graphic. The larger the area below the curve, the better our model will be at predicting the outcomes, and avoid both false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPR, TPR, _ = roc_curve(y_test, predictions)\n",
    "roc_score=round(100*roc_auc_score(y_test, predictions),1)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines",
         "name": "AUC: 78.5",
         "type": "scatter",
         "uid": "f0b6e3ff-a53e-4652-a9da-d95adc25269b",
         "x": [
          0,
          0.10962757245602792,
          1
         ],
         "y": [
          0,
          0.68,
          1
         ]
        },
        {
         "mode": "lines",
         "name": "Baseline Area: 50.0",
         "type": "scatter",
         "uid": "ea911e1f-19e0-49ce-9ce7-4b8535a2a61b",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "height": 600,
        "title": {
         "text": "Receiver Operating Characteristic - Area Under Curve"
        },
        "width": 650
       }
      },
      "text/html": [
       "<div id=\"de013f37-3210-46a3-94af-7012450e0f3f\" style=\"height: 600px; width: 650px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"de013f37-3210-46a3-94af-7012450e0f3f\")) {\n",
       "    Plotly.newPlot(\"de013f37-3210-46a3-94af-7012450e0f3f\", [{\"mode\": \"lines\", \"name\": \"AUC: 78.5\", \"x\": [0.0, 0.10962757245602792, 1.0], \"y\": [0.0, 0.68, 1.0], \"type\": \"scatter\", \"uid\": \"f0b6e3ff-a53e-4652-a9da-d95adc25269b\"}, {\"mode\": \"lines\", \"name\": \"Baseline Area: 50.0\", \"x\": [0, 1], \"y\": [0, 1], \"type\": \"scatter\", \"uid\": \"ea911e1f-19e0-49ce-9ce7-4b8535a2a61b\"}], {\"height\": 600, \"title\": {\"text\": \"Receiver Operating Characteristic - Area Under Curve\"}, \"width\": 650}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"de013f37-3210-46a3-94af-7012450e0f3f\" style=\"height: 600px; width: 650px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"de013f37-3210-46a3-94af-7012450e0f3f\")) {\n",
       "    Plotly.newPlot(\"de013f37-3210-46a3-94af-7012450e0f3f\", [{\"mode\": \"lines\", \"name\": \"AUC: 78.5\", \"x\": [0.0, 0.10962757245602792, 1.0], \"y\": [0.0, 0.68, 1.0], \"type\": \"scatter\", \"uid\": \"f0b6e3ff-a53e-4652-a9da-d95adc25269b\"}, {\"mode\": \"lines\", \"name\": \"Baseline Area: 50.0\", \"x\": [0, 1], \"y\": [0, 1], \"type\": \"scatter\", \"uid\": \"ea911e1f-19e0-49ce-9ce7-4b8535a2a61b\"}], {\"height\": 600, \"title\": {\"text\": \"Receiver Operating Characteristic - Area Under Curve\"}, \"width\": 650}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC-AUC figure\n",
    "\n",
    "data = [\n",
    "    {\n",
    "      'x':FPR, \n",
    "      'y':TPR, \n",
    "      'type':'scatter',\n",
    "      'mode': 'lines',\n",
    "      'name': 'AUC: '+str(roc_score)\n",
    "      },\n",
    "     {'x':[0,1], \n",
    "      'y':[0,1], \n",
    "      'type':'scatter',\n",
    "      'mode': 'lines',\n",
    "      'name': 'Baseline Area: 50.0'}]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Receiver Operating Characteristic - Area Under Curve',\n",
    "    width=650,\n",
    "    height=600, \n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of evaluating our model is the `confusion matrix`, which displays actual counts for true positives, false negatives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix tells us our false positives and false negatives:\n",
    "matrix=confusion_matrix(y_test, predictions)\n",
    "cm=pd.DataFrame(matrix, columns=['predicted: +', 'predicted: -'], index=['ground truth: +', 'ground truth: -'])\n",
    "cm=cm.reset_index(drop=False)\n",
    "cm=cm.rename(columns={'index': f'n = {len(y_test)}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#00083e"
          ],
          [
           0.5,
           "#ededee"
          ],
          [
           1,
           "#ffffff"
          ]
         ],
         "hoverinfo": "none",
         "opacity": 0.75,
         "showscale": false,
         "type": "heatmap",
         "uid": "e419205b-8782-4508-a244-8b04ff136344",
         "z": [
          [
           0,
           0,
           0
          ],
          [
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>n = 28111</b>",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>predicted: +</b>",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>predicted: -</b>",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "ground truth: +",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "25007",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "3079",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "ground truth: -",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "8",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "17",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         }
        ],
        "height": 140,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "xaxis": {
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": -0.5,
         "ticks": "",
         "zeroline": false
        },
        "yaxis": {
         "autorange": "reversed",
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": 0.5,
         "ticks": "",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"b3300019-66c7-4cf2-8ec6-edff4866322a\" style=\"height: 140px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\")) {\n",
       "    Plotly.newPlot(\"b3300019-66c7-4cf2-8ec6-edff4866322a\", [{\"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"hoverinfo\": \"none\", \"opacity\": 0.75, \"showscale\": false, \"z\": [[0, 0, 0], [0.5, 0.5, 0.5], [1, 1, 1]], \"type\": \"heatmap\", \"uid\": \"e419205b-8782-4508-a244-8b04ff136344\"}], {\"annotations\": [{\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>n = 28111</b>\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: +</b>\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: -</b>\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: +\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"25007\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"3079\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: -\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"8\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"17\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}], \"height\": 140, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"xaxis\": {\"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\")) {window._Plotly.Plots.resize(document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"b3300019-66c7-4cf2-8ec6-edff4866322a\" style=\"height: 140px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\")) {\n",
       "    Plotly.newPlot(\"b3300019-66c7-4cf2-8ec6-edff4866322a\", [{\"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"hoverinfo\": \"none\", \"opacity\": 0.75, \"showscale\": false, \"z\": [[0, 0, 0], [0.5, 0.5, 0.5], [1, 1, 1]], \"type\": \"heatmap\", \"uid\": \"e419205b-8782-4508-a244-8b04ff136344\"}], {\"annotations\": [{\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>n = 28111</b>\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: +</b>\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: -</b>\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: +\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"25007\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"3079\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: -\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"8\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"17\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}], \"height\": 140, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"xaxis\": {\"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\")) {window._Plotly.Plots.resize(document.getElementById(\"b3300019-66c7-4cf2-8ec6-edff4866322a\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "table = ff.create_table(cm)\n",
    "iplot(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the results \n",
    "with open('confu_matrix6.pkl', 'wb') as f:\n",
    "    pickle.dump(cm, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Evaluation Metrics\n",
    "\n",
    "Accuracy:\n",
    "Overall, how often is it correct?\n",
    "(TP + TN) / total\n",
    "\n",
    "Sensitivity (Recall):\n",
    "When actual value is positive, how often is prediction correct?\n",
    "TP / actual yes\n",
    "“True Positive Rate” or “Recall”\n",
    "\n",
    "Precision:\n",
    "TP / (TP + FP)\n",
    "\n",
    "Specificity:\n",
    "When actual value is negative, how often is prediction correct?\n",
    "TN / actual no\n",
    "\n",
    "Misclassification Rate (Error Rate):\n",
    "Overall, how often is it wrong?\n",
    "(FP + FN) / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of logistic regression is that it can tell us not only which features are associated with the outcome, but the size and directionality of that association. This is called `feature importance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Interpretation of the coefficients](http://kevinyuan.ca/2016/08/01/Interpreting-Logistic-Regression/) can be challenging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "results=pd.DataFrame(list(zip(X_test.columns, logreg.coef_[0])), columns=['feature', 'coefficient'])\n",
    "results=results.sort_values(by='coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_coeffs=results.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept term from the logistic regression is the log odds of our base reference term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0998009])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To interpret the coefficients, add them to the intercept and then read as odds ratios.\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding any other coefficient to the intercept gives the log odds of failure for that feature. For example, an increase of one unit in attribute 4 decreases the odds of failure (i.e., makes it more likely not to fail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute4</td>\n",
       "      <td>0.535093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>attribute4_lag01</td>\n",
       "      <td>0.469254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attribute2_lag01</td>\n",
       "      <td>0.417921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attribute2</td>\n",
       "      <td>0.417046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>attribute4_lag02</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attribute2_lag02</td>\n",
       "      <td>0.367693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attribute4_lag03</td>\n",
       "      <td>0.364203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>attribute7_lag01</td>\n",
       "      <td>0.353935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attribute7</td>\n",
       "      <td>0.352449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>attribute2_lag03</td>\n",
       "      <td>0.327986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>attribute2_lag04</td>\n",
       "      <td>0.316946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>attribute4_lag04</td>\n",
       "      <td>0.304469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>attribute7_lag03</td>\n",
       "      <td>0.292580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>attribute7_lag02</td>\n",
       "      <td>0.276835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>attribute7_lag04</td>\n",
       "      <td>0.255710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "3         attribute4     0.535093\n",
       "21  attribute4_lag01     0.469254\n",
       "13  attribute2_lag01     0.417921\n",
       "1         attribute2     0.417046\n",
       "22  attribute4_lag02     0.406024\n",
       "14  attribute2_lag02     0.367693\n",
       "23  attribute4_lag03     0.364203\n",
       "33  attribute7_lag01     0.353935\n",
       "6         attribute7     0.352449\n",
       "15  attribute2_lag03     0.327986\n",
       "16  attribute2_lag04     0.316946\n",
       "24  attribute4_lag04     0.304469\n",
       "35  attribute7_lag03     0.292580\n",
       "34  attribute7_lag02     0.276835\n",
       "36  attribute7_lag04     0.255710"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the regression coefficients from greatest to smallest.\n",
    "big_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           "#fde725",
           "#d8e219",
           "#addc30",
           "#84d44b",
           "#5ec962",
           "#3fbc73",
           "#28ae80",
           "#1fa088",
           "#21918c",
           "#26828e",
           "#2c728e",
           "#33638d",
           "#3b528b",
           "#424086",
           "#472d7b",
           "#48186a",
           "#440154"
          ]
         },
         "type": "bar",
         "uid": "e84bb508-59c2-47ed-8241-f81653169aa0",
         "x": [
          "attribute4",
          "attribute4_lag01",
          "attribute2_lag01",
          "attribute2",
          "attribute4_lag02",
          "attribute2_lag02",
          "attribute4_lag03",
          "attribute7_lag01",
          "attribute7",
          "attribute2_lag03",
          "attribute2_lag04",
          "attribute4_lag04",
          "attribute7_lag03",
          "attribute7_lag02",
          "attribute7_lag04"
         ],
         "y": [
          0.5350934960201712,
          0.46925431585376803,
          0.41792054739632484,
          0.4170460868760466,
          0.4060243375752158,
          0.3676933294974366,
          0.36420276930316614,
          0.35393474842525274,
          0.3524494405221047,
          0.3279858734687821,
          0.31694558329905065,
          0.3044689630216918,
          0.2925797205665989,
          0.276835143180643,
          0.25571001136005544
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Logistic Regression Results"
        },
        "xaxis": {
         "title": {
          "text": "Coefficients"
         }
        },
        "yaxis": {
         "title": {
          "text": "Odds Ratio to Failure"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\")) {\n",
       "    Plotly.newPlot(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\", [{\"marker\": {\"color\": [\"#fde725\", \"#d8e219\", \"#addc30\", \"#84d44b\", \"#5ec962\", \"#3fbc73\", \"#28ae80\", \"#1fa088\", \"#21918c\", \"#26828e\", \"#2c728e\", \"#33638d\", \"#3b528b\", \"#424086\", \"#472d7b\", \"#48186a\", \"#440154\"]}, \"x\": [\"attribute4\", \"attribute4_lag01\", \"attribute2_lag01\", \"attribute2\", \"attribute4_lag02\", \"attribute2_lag02\", \"attribute4_lag03\", \"attribute7_lag01\", \"attribute7\", \"attribute2_lag03\", \"attribute2_lag04\", \"attribute4_lag04\", \"attribute7_lag03\", \"attribute7_lag02\", \"attribute7_lag04\"], \"y\": [0.5350934960201712, 0.46925431585376803, 0.41792054739632484, 0.4170460868760466, 0.4060243375752158, 0.3676933294974366, 0.36420276930316614, 0.35393474842525274, 0.3524494405221047, 0.3279858734687821, 0.31694558329905065, 0.3044689630216918, 0.2925797205665989, 0.276835143180643, 0.25571001136005544], \"type\": \"bar\", \"uid\": \"e84bb508-59c2-47ed-8241-f81653169aa0\"}], {\"title\": {\"text\": \"Logistic Regression Results\"}, \"xaxis\": {\"title\": {\"text\": \"Coefficients\"}}, \"yaxis\": {\"title\": {\"text\": \"Odds Ratio to Failure\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\")) {window._Plotly.Plots.resize(document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\")) {\n",
       "    Plotly.newPlot(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\", [{\"marker\": {\"color\": [\"#fde725\", \"#d8e219\", \"#addc30\", \"#84d44b\", \"#5ec962\", \"#3fbc73\", \"#28ae80\", \"#1fa088\", \"#21918c\", \"#26828e\", \"#2c728e\", \"#33638d\", \"#3b528b\", \"#424086\", \"#472d7b\", \"#48186a\", \"#440154\"]}, \"x\": [\"attribute4\", \"attribute4_lag01\", \"attribute2_lag01\", \"attribute2\", \"attribute4_lag02\", \"attribute2_lag02\", \"attribute4_lag03\", \"attribute7_lag01\", \"attribute7\", \"attribute2_lag03\", \"attribute2_lag04\", \"attribute4_lag04\", \"attribute7_lag03\", \"attribute7_lag02\", \"attribute7_lag04\"], \"y\": [0.5350934960201712, 0.46925431585376803, 0.41792054739632484, 0.4170460868760466, 0.4060243375752158, 0.3676933294974366, 0.36420276930316614, 0.35393474842525274, 0.3524494405221047, 0.3279858734687821, 0.31694558329905065, 0.3044689630216918, 0.2925797205665989, 0.276835143180643, 0.25571001136005544], \"type\": \"bar\", \"uid\": \"e84bb508-59c2-47ed-8241-f81653169aa0\"}], {\"title\": {\"text\": \"Logistic Regression Results\"}, \"xaxis\": {\"title\": {\"text\": \"Coefficients\"}}, \"yaxis\": {\"title\": {\"text\": \"Odds Ratio to Failure\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\")) {window._Plotly.Plots.resize(document.getElementById(\"64d908a5-a09a-4d38-b5d7-5b65978fe66b\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display that with Plotly.\n",
    "mydata = [go.Bar(\n",
    "    x=big_coeffs['feature'],\n",
    "    y=big_coeffs['coefficient'],\n",
    "    marker=dict(color=Viridis[::-1])\n",
    ")]\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title='Logistic Regression Results',\n",
    "    xaxis = dict(title = 'Coefficients'), \n",
    "    yaxis = dict(title = 'Odds Ratio to Failure'), \n",
    "\n",
    ")\n",
    "fig = go.Figure(data=mydata, layout=mylayout)\n",
    "pio.write_image(fig, '../images/logistic.png')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Were these features highly correlated with the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attribute4',\n",
       " 'attribute4_lag01',\n",
       " 'attribute2_lag01',\n",
       " 'attribute2',\n",
       " 'attribute4_lag02',\n",
       " 'failure']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(big_coeffs.feature)[:5]\n",
    "cols.append('failure')\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the features, by itself, has a high correlation with failure. This explains in part why our model doesn't have greater predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute4_lag01</th>\n",
       "      <th>attribute2_lag01</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute4_lag02</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>attribute4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991320</td>\n",
       "      <td>0.209833</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.983055</td>\n",
       "      <td>0.064157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute4_lag01</th>\n",
       "      <td>0.991320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.991663</td>\n",
       "      <td>0.056897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute2_lag01</th>\n",
       "      <td>0.209833</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991008</td>\n",
       "      <td>0.207976</td>\n",
       "      <td>0.058904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute2</th>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.991008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>0.059865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute4_lag02</th>\n",
       "      <td>0.983055</td>\n",
       "      <td>0.991663</td>\n",
       "      <td>0.207976</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failure</th>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.056897</td>\n",
       "      <td>0.058904</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  attribute4  attribute4_lag01  attribute2_lag01  attribute2  \\\n",
       "attribute4          1.000000          0.991320          0.209833    0.213120   \n",
       "attribute4_lag01    0.991320          1.000000          0.210570    0.210180   \n",
       "attribute2_lag01    0.209833          0.210570          1.000000    0.991008   \n",
       "attribute2          0.213120          0.210180          0.991008    1.000000   \n",
       "attribute4_lag02    0.983055          0.991663          0.207976    0.206883   \n",
       "failure             0.064157          0.056897          0.058904    0.059865   \n",
       "\n",
       "                  attribute4_lag02   failure  \n",
       "attribute4                0.983055  0.064157  \n",
       "attribute4_lag01          0.991663  0.056897  \n",
       "attribute2_lag01          0.207976  0.058904  \n",
       "attribute2                0.206883  0.059865  \n",
       "attribute4_lag02          1.000000  0.052150  \n",
       "failure                   0.052150  1.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].corr()\n",
    "# No, they were not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are we accurate when aggregated to the device level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts probability of failure on a daily basis, but we might also want to know about probability that a device will fail at any point in its life. A confusion matrix will help us determine whether our model successfully predicts failure over the life of a device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:  28111\n",
      "probabilities:  28111\n",
      "combined:  28111\n"
     ]
    }
   ],
   "source": [
    "y1_test=y1_test.reset_index(drop=True) # for the concat to work correctly, must have a clean index.\n",
    "preds_df=pd.DataFrame(predictions, columns=['preds'])\n",
    "combined_testdf=pd.concat([y1_test, preds_df], axis=1)\n",
    "\n",
    "print('y_test: ', len(y1_test))\n",
    "print('probabilities: ', len(preds_df))\n",
    "print('combined: ', len(combined_testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1F0S68M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z1F1R76A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1F16RA7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1F131F6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1F14GTK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     device  failure  preds\n",
       "0  S1F0S68M        0      0\n",
       "1  Z1F1R76A        0      0\n",
       "2  W1F16RA7        0      0\n",
       "3  S1F131F6        0      0\n",
       "4  W1F14GTK        0      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(676, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1F01XDJ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1F023H2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1F02L38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1F03YZM</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     device   failure     preds\n",
       "0  S1F01E6Y  0.000000  0.000000\n",
       "1  S1F01XDJ  0.000000  0.000000\n",
       "2  S1F023H2  0.166667  0.833333\n",
       "3  S1F02L38  0.000000  0.000000\n",
       "4  S1F03YZM  0.012821  0.461538"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf=combined_testdf.groupby('device')[['device', 'failure', 'preds']].mean().reset_index(drop=False)\n",
    "print(aggdf.shape)\n",
    "aggdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    651\n",
       "1     25\n",
       "Name: failed, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf['failed']=0\n",
    "aggdf.loc[aggdf['failure']>0, 'failed']=1\n",
    "aggdf['failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    536\n",
       "1    140\n",
       "Name: pred_failed, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf['pred_failed']=0\n",
    "aggdf.loc[aggdf['preds']>0, 'pred_failed']=1\n",
    "aggdf['pred_failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_failed</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528</td>\n",
       "      <td>123</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>536</td>\n",
       "      <td>140</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_failed    0    1  All\n",
       "failed                    \n",
       "0            528  123  651\n",
       "1              8   17   25\n",
       "All          536  140  676"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix (device level)\n",
    "pd.crosstab(aggdf['failed'], aggdf['pred_failed'],  margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification model does a poor job of identifying true negatives. It only identifies 13% of failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93701, 39)\n"
     ]
    }
   ],
   "source": [
    "combined_testdf.to_csv('../data/dataset6.gz', compression='gzip', index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
